{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "659a762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from utilities import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "573fa97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 398, 398, 32)      320       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 132, 132, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 130, 130, 16)      4624      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 65, 65, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 63, 63, 8)         1160      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 31, 31, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7688)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 7689      \n",
      "=================================================================\n",
      "Total params: 13,793\n",
      "Trainable params: 13,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 2s 289ms/step - loss: 0.7669 - acc: 0.3906\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 2s 295ms/step - loss: 0.7245 - acc: 0.4688\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 2s 290ms/step - loss: 0.7032 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 2s 275ms/step - loss: 0.7146 - acc: 0.5000\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 2s 277ms/step - loss: 0.6942 - acc: 0.4844\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 2s 273ms/step - loss: 0.7009 - acc: 0.4844\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 2s 276ms/step - loss: 0.7066 - acc: 0.5156\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 2s 276ms/step - loss: 0.6660 - acc: 0.6719\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 2s 300ms/step - loss: 0.6811 - acc: 0.5000\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 2s 268ms/step - loss: 0.6715 - acc: 0.6094\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.6673 - acc: 0.7031\n",
      "Test set : \n",
      "\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6969 - acc: 0.5625\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 2s 269ms/step - loss: 0.7686 - acc: 0.4844\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 2s 267ms/step - loss: 0.7269 - acc: 0.5156\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 2s 270ms/step - loss: 0.7068 - acc: 0.5156\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 2s 278ms/step - loss: 0.6960 - acc: 0.4219\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 2s 281ms/step - loss: 0.6914 - acc: 0.5938\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 2s 270ms/step - loss: 0.6859 - acc: 0.4844\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 2s 272ms/step - loss: 0.6799 - acc: 0.6094\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 2s 268ms/step - loss: 0.6751 - acc: 0.6406\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 2s 270ms/step - loss: 0.6789 - acc: 0.5625\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 2s 265ms/step - loss: 0.6907 - acc: 0.5000\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.6790 - acc: 0.5000\n",
      "Test set : \n",
      "\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7233 - acc: 0.4375\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 2s 280ms/step - loss: 0.7670 - acc: 0.4375\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 2s 275ms/step - loss: 0.7247 - acc: 0.5000\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 2s 279ms/step - loss: 0.7033 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 2s 277ms/step - loss: 0.6939 - acc: 0.5469\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 2s 276ms/step - loss: 0.6881 - acc: 0.5156\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 2s 292ms/step - loss: 0.6803 - acc: 0.5625\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 2s 289ms/step - loss: 0.6773 - acc: 0.5156\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 2s 279ms/step - loss: 0.7040 - acc: 0.5469\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 2s 278ms/step - loss: 0.6723 - acc: 0.5625\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 2s 277ms/step - loss: 0.6729 - acc: 0.5938\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D11CF1E4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 0.6581 - acc: 0.6406\n",
      "Test set : \n",
      "\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D11CF1E4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.7044 - acc: 0.5000\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 2s 271ms/step - loss: 0.7642 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 2s 289ms/step - loss: 0.7316 - acc: 0.5000\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 2s 271ms/step - loss: 0.7076 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 2s 270ms/step - loss: 0.6995 - acc: 0.5469\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 2s 273ms/step - loss: 0.6960 - acc: 0.4531\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 2s 270ms/step - loss: 0.6926 - acc: 0.5000\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 2s 270ms/step - loss: 0.6918 - acc: 0.4375\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 2s 288ms/step - loss: 0.6865 - acc: 0.4688\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 2s 277ms/step - loss: 0.6670 - acc: 0.5469\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 2s 268ms/step - loss: 0.6625 - acc: 0.6094\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "WARNING:tensorflow:7 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D11BB25E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 200ms/step - loss: 0.6459 - acc: 0.9062\n",
      "Test set : \n",
      "\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D11BB25E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6482 - acc: 0.7500\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 2s 275ms/step - loss: 0.7641 - acc: 0.4844\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 2s 277ms/step - loss: 0.7207 - acc: 0.4688\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 2s 278ms/step - loss: 0.6995 - acc: 0.5469\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 0.6855 - acc: 0.5469\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 2s 279ms/step - loss: 0.6750 - acc: 0.6406\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 2s 284ms/step - loss: 0.6775 - acc: 0.5469\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 2s 279ms/step - loss: 0.6556 - acc: 0.6875\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 2s 280ms/step - loss: 0.6427 - acc: 0.7812\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 2s 280ms/step - loss: 0.6768 - acc: 0.6094\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 0.6346 - acc: 0.6250\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D11BC99700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.6459 - acc: 0.6406\n",
      "Test set : \n",
      "\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D11BC99700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.7010 - acc: 0.5000\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "data amount of 80 leading to accuracy of 55.0 +- 10.752906583803284\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 398, 398, 32)      320       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_18 (Averag (None, 132, 132, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 130, 130, 16)      4624      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_19 (Averag (None, 65, 65, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 63, 63, 8)         1160      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_20 (Averag (None, 31, 31, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 7688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 7689      \n",
      "=================================================================\n",
      "Total params: 13,793\n",
      "Trainable params: 13,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.7607 - acc: 0.4896\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7120 - acc: 0.5104\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.6958 - acc: 0.4792\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 0.6901 - acc: 0.5625\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.6902 - acc: 0.5938\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.6776 - acc: 0.6354\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.6678 - acc: 0.6042\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 0.6407 - acc: 0.5729\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.6156 - acc: 0.6979\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.6977 - acc: 0.5104\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D10E1DF9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 1s 260ms/step - loss: 0.6575 - acc: 0.4896\n",
      "Test set : \n",
      "\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D10E1DF9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 971us/step - loss: 0.7110 - acc: 0.3750\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 0.7670 - acc: 0.4792\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 4s 357ms/step - loss: 0.7209 - acc: 0.3958\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 0.7010 - acc: 0.4896\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 0.6904 - acc: 0.5521\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 0.6854 - acc: 0.5521\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 4s 356ms/step - loss: 0.6871 - acc: 0.5729\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 0.6905 - acc: 0.5417\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 0.6819 - acc: 0.6250\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 0.6772 - acc: 0.5312\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 4s 352ms/step - loss: 0.6677 - acc: 0.6042\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D11BB255E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 1s 263ms/step - loss: 0.6509 - acc: 0.5833\n",
      "Test set : \n",
      "\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D11BB255E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 147us/step - loss: 0.6838 - acc: 0.5417\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 0.7591 - acc: 0.4583\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 0.7103 - acc: 0.4792\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 0.7000 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 4s 352ms/step - loss: 0.6971 - acc: 0.4167\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 0.7016 - acc: 0.5000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 0.6902 - acc: 0.5833\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 0.6908 - acc: 0.5417\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 0.6987 - acc: 0.5000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 4s 352ms/step - loss: 0.7022 - acc: 0.4583\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 0.6779 - acc: 0.6458\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D11A09B310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 1s 268ms/step - loss: 0.6806 - acc: 0.5000\n",
      "Test set : \n",
      "\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D11A09B310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6709 - acc: 0.5000\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 0.7579 - acc: 0.5208\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 0.7082 - acc: 0.5625\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.6925 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.6822 - acc: 0.5729\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.6789 - acc: 0.4792\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 3s 345ms/step - loss: 0.6559 - acc: 0.5729\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.6456 - acc: 0.5208\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.6075 - acc: 0.6875\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.5813 - acc: 0.7083\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 3s 344ms/step - loss: 0.5764 - acc: 0.7500\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D1181B48B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 1s 258ms/step - loss: 0.5180 - acc: 0.6875\n",
      "Test set : \n",
      "\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D1181B48B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5766 - acc: 0.6667\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 0.7572 - acc: 0.4896\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 0.7095 - acc: 0.5312\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 0.6936 - acc: 0.4479\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 353ms/step - loss: 0.6880 - acc: 0.5417\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.6850 - acc: 0.4583\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 4s 361ms/step - loss: 0.6757 - acc: 0.5833\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.6759 - acc: 0.5521\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.6609 - acc: 0.6146\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.6441 - acc: 0.7083\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.6706 - acc: 0.6250\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D119FBEE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 1s 243ms/step - loss: 0.5968 - acc: 0.8125\n",
      "Test set : \n",
      "\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D119FBEE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 972us/step - loss: 0.6635 - acc: 0.6250\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "data amount of 120 leading to accuracy of 54.166667461395264 +- 10.206207748266497\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 398, 398, 32)      320       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_33 (Averag (None, 132, 132, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 130, 130, 16)      4624      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_34 (Averag (None, 65, 65, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 63, 63, 8)         1160      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_35 (Averag (None, 31, 31, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 7688)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 7689      \n",
      "=================================================================\n",
      "Total params: 13,793\n",
      "Trainable params: 13,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 6s 413ms/step - loss: 0.7520 - acc: 0.4750\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 6s 400ms/step - loss: 0.7048 - acc: 0.5000\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 6s 399ms/step - loss: 0.6940 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 6s 416ms/step - loss: 0.6932 - acc: 0.5125\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 6s 402ms/step - loss: 0.6955 - acc: 0.5375\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 6s 409ms/step - loss: 0.6927 - acc: 0.5125\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 6s 402ms/step - loss: 0.6967 - acc: 0.5312\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 6s 400ms/step - loss: 0.7218 - acc: 0.4563\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 6s 417ms/step - loss: 0.7005 - acc: 0.5063\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 6s 397ms/step - loss: 0.6843 - acc: 0.5688\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D11D8B0550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "5/5 [==============================] - 2s 311ms/step - loss: 0.6739 - acc: 0.5875\n",
      "Test set : \n",
      "\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D11D8B0550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6695 - acc: 0.6000\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 6s 427ms/step - loss: 0.7526 - acc: 0.5063\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 6s 414ms/step - loss: 0.7074 - acc: 0.4812\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 6s 423ms/step - loss: 0.6954 - acc: 0.4875\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 6s 449ms/step - loss: 0.6911 - acc: 0.4313\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 6s 428ms/step - loss: 0.6936 - acc: 0.5063\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 6s 433ms/step - loss: 0.6818 - acc: 0.6000\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 6s 417ms/step - loss: 0.6850 - acc: 0.5813\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 6s 421ms/step - loss: 0.6760 - acc: 0.5375\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 6s 420ms/step - loss: 0.6760 - acc: 0.5688\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 6s 413ms/step - loss: 0.6580 - acc: 0.6313\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D1181B49D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 316ms/step - loss: 0.6630 - acc: 0.5562\n",
      "Test set : \n",
      "\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.7056 - acc: 0.5250\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 6s 418ms/step - loss: 0.7523 - acc: 0.4812\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 6s 413ms/step - loss: 0.7038 - acc: 0.5125\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 6s 422ms/step - loss: 0.6916 - acc: 0.5500\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 6s 420ms/step - loss: 0.6908 - acc: 0.5437\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 6s 419ms/step - loss: 0.6800 - acc: 0.5938\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 6s 419ms/step - loss: 0.6913 - acc: 0.5000\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 6s 415ms/step - loss: 0.6849 - acc: 0.5125\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 6s 427ms/step - loss: 0.6590 - acc: 0.5938\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 6s 416ms/step - loss: 0.6025 - acc: 0.6438\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 6s 416ms/step - loss: 0.5826 - acc: 0.6625\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D119ACA160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "5/5 [==============================] - 2s 321ms/step - loss: 0.5193 - acc: 0.7312\n",
      "Test set : \n",
      "\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5313 - acc: 0.7000\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 5s 386ms/step - loss: 0.7511 - acc: 0.4688\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 5s 384ms/step - loss: 0.7022 - acc: 0.4688\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 6s 397ms/step - loss: 0.6980 - acc: 0.4688\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 5s 384ms/step - loss: 0.6898 - acc: 0.4812\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 6s 394ms/step - loss: 0.6807 - acc: 0.5625\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 5s 386ms/step - loss: 0.7012 - acc: 0.4812\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 5s 381ms/step - loss: 0.7041 - acc: 0.4062\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 6s 397ms/step - loss: 0.6732 - acc: 0.6375\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 5s 384ms/step - loss: 0.6778 - acc: 0.5625\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 5s 378ms/step - loss: 0.6810 - acc: 0.5437\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D119ACA310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "5/5 [==============================] - 2s 302ms/step - loss: 0.6624 - acc: 0.7375\n",
      "Test set : \n",
      "\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6838 - acc: 0.6750\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 6s 412ms/step - loss: 0.7476 - acc: 0.4812\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 6s 414ms/step - loss: 0.7017 - acc: 0.5063\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 6s 418ms/step - loss: 0.6924 - acc: 0.5562\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 6s 408ms/step - loss: 0.7005 - acc: 0.5625\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 6s 409ms/step - loss: 0.7028 - acc: 0.5188\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 6s 411ms/step - loss: 0.6926 - acc: 0.5375\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 6s 403ms/step - loss: 0.6903 - acc: 0.5188\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 6s 418ms/step - loss: 0.6812 - acc: 0.5750\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 6s 406ms/step - loss: 0.6835 - acc: 0.5250\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 6s 402ms/step - loss: 0.6730 - acc: 0.5375\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D11BB25550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "5/5 [==============================] - 2s 330ms/step - loss: 0.6749 - acc: 0.6187\n",
      "Test set : \n",
      "\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6913 - acc: 0.5500\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "data amount of 200 leading to accuracy of 61.00000023841858 +- 6.819091075755228\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_48 (Conv2D)           (None, 398, 398, 32)      320       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_48 (Averag (None, 132, 132, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 130, 130, 16)      4624      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_49 (Averag (None, 65, 65, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 63, 63, 8)         1160      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_50 (Averag (None, 31, 31, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 7688)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 7689      \n",
      "=================================================================\n",
      "Total params: 13,793\n",
      "Trainable params: 13,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 12s 543ms/step - loss: 0.7342 - acc: 0.5125\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 12s 535ms/step - loss: 0.6943 - acc: 0.5156\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 12s 540ms/step - loss: 0.6812 - acc: 0.5719\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 12s 534ms/step - loss: 0.6855 - acc: 0.4938\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 12s 539ms/step - loss: 0.6607 - acc: 0.6125\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 0.6510 - acc: 0.5469\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 12s 527ms/step - loss: 0.5663 - acc: 0.7281\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 12s 524ms/step - loss: 0.3571 - acc: 0.8781\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 12s 524ms/step - loss: 0.2832 - acc: 0.9281\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 0.2674 - acc: 0.9312\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D10E1DF280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "10/10 [==============================] - 4s 364ms/step - loss: 0.1372 - acc: 1.0000\n",
      "Test set : \n",
      "\n",
      "3/3 [==============================] - 1s 183ms/step - loss: 0.1449 - acc: 1.0000\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 11s 502ms/step - loss: 0.7341 - acc: 0.4906\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 11s 504ms/step - loss: 0.7078 - acc: 0.5031\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 11s 511ms/step - loss: 0.6955 - acc: 0.4844\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 11s 508ms/step - loss: 0.6969 - acc: 0.4844\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 11s 499ms/step - loss: 0.6887 - acc: 0.5000\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 11s 509ms/step - loss: 0.6838 - acc: 0.5531\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 11s 508ms/step - loss: 0.6843 - acc: 0.5469\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 11s 506ms/step - loss: 0.6373 - acc: 0.6719\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 11s 502ms/step - loss: 0.7237 - acc: 0.5406\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 0.6160 - acc: 0.6438\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.8917 - acc: 0.5688\n",
      "Test set : \n",
      "\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 0.9836 - acc: 0.5250\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 12s 540ms/step - loss: 0.7519 - acc: 0.4750\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 12s 544ms/step - loss: 0.7052 - acc: 0.4594\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 12s 543ms/step - loss: 0.6932 - acc: 0.4875\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 12s 540ms/step - loss: 0.6855 - acc: 0.5906\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 12s 542ms/step - loss: 0.6896 - acc: 0.5750\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 12s 545ms/step - loss: 0.6908 - acc: 0.5562\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 12s 546ms/step - loss: 0.6837 - acc: 0.4969\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 12s 558ms/step - loss: 0.6970 - acc: 0.5594\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 12s 550ms/step - loss: 0.6870 - acc: 0.5344\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 12s 548ms/step - loss: 0.6369 - acc: 0.7031\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "10/10 [==============================] - 4s 362ms/step - loss: 0.6610 - acc: 0.5719\n",
      "Test set : \n",
      "\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 0.6622 - acc: 0.5500\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 12s 548ms/step - loss: 0.7309 - acc: 0.4625\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 12s 543ms/step - loss: 0.6964 - acc: 0.5312\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 12s 540ms/step - loss: 0.6954 - acc: 0.4656\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 12s 539ms/step - loss: 0.6799 - acc: 0.6906\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 12s 537ms/step - loss: 0.6749 - acc: 0.5375\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 12s 534ms/step - loss: 0.6767 - acc: 0.5875\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 12s 540ms/step - loss: 0.6463 - acc: 0.6187\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 12s 541ms/step - loss: 0.6293 - acc: 0.62190s - loss: 0.6293 - acc: 0.621\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 12s 540ms/step - loss: 0.6362 - acc: 0.5625\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 12s 531ms/step - loss: 0.5386 - acc: 0.7000\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "10/10 [==============================] - 4s 357ms/step - loss: 0.6324 - acc: 0.6344\n",
      "Test set : \n",
      "\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.6636 - acc: 0.6500\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 0.7327 - acc: 0.4938\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 11s 511ms/step - loss: 0.6947 - acc: 0.4812\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 0.6928 - acc: 0.4844\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 12s 533ms/step - loss: 0.7023 - acc: 0.5469\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 10s 457ms/step - loss: 0.7026 - acc: 0.5125\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.6973 - acc: 0.5125\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.6642 - acc: 0.6500\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 10s 457ms/step - loss: 0.6745 - acc: 0.6438\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.6605 - acc: 0.5969\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.6067 - acc: 0.6281\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 0.4711 - acc: 0.7844\n",
      "Test set : \n",
      "\n",
      "3/3 [==============================] - 1s 184ms/step - loss: 0.4977 - acc: 0.7875\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "data amount of 400 leading to accuracy of 70.24999976158142 +- 17.507142050288444\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_63 (Conv2D)           (None, 398, 398, 32)      320       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_63 (Averag (None, 132, 132, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 130, 130, 16)      4624      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_64 (Averag (None, 65, 65, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 63, 63, 8)         1160      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_65 (Averag (None, 31, 31, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 7688)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 7689      \n",
      "=================================================================\n",
      "Total params: 13,793\n",
      "Trainable params: 13,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 18s 883ms/step - loss: 0.7337 - acc: 0.4688\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 18s 883ms/step - loss: 0.6954 - acc: 0.4938\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 17s 875ms/step - loss: 0.6877 - acc: 0.5437\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 17s 873ms/step - loss: 0.7031 - acc: 0.5104\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 18s 877ms/step - loss: 0.6850 - acc: 0.5437\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 18s 877ms/step - loss: 0.6539 - acc: 0.6083\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 18s 877ms/step - loss: 0.5470 - acc: 0.7354\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 18s 878ms/step - loss: 0.5141 - acc: 0.6979\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 17s 874ms/step - loss: 0.5347 - acc: 0.7312\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 17s 875ms/step - loss: 0.2087 - acc: 0.9771\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "15/15 [==============================] - 6s 370ms/step - loss: 0.1398 - acc: 0.9854\n",
      "Test set : \n",
      "\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.1468 - acc: 0.9833\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 18s 886ms/step - loss: 0.7325 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 18s 876ms/step - loss: 0.6959 - acc: 0.5167\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 17s 873ms/step - loss: 0.7005 - acc: 0.4833\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 18s 879ms/step - loss: 0.6980 - acc: 0.4875\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 17s 871ms/step - loss: 0.6912 - acc: 0.5167\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 17s 874ms/step - loss: 0.6903 - acc: 0.5396\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 18s 884ms/step - loss: 0.6788 - acc: 0.5562\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 18s 877ms/step - loss: 0.6887 - acc: 0.5271\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 17s 871ms/step - loss: 0.6453 - acc: 0.7146\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 17s 867ms/step - loss: 0.7030 - acc: 0.5250\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "15/15 [==============================] - 5s 321ms/step - loss: 0.6959 - acc: 0.5396\n",
      "Test set : \n",
      "\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.7102 - acc: 0.5250\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 17s 860ms/step - loss: 0.7340 - acc: 0.4979\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 17s 862ms/step - loss: 0.6966 - acc: 0.5875\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 17s 861ms/step - loss: 0.6950 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 17s 861ms/step - loss: 0.6891 - acc: 0.5458\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 17s 862ms/step - loss: 0.6717 - acc: 0.6167\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 17s 869ms/step - loss: 0.6534 - acc: 0.6250\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 17s 867ms/step - loss: 0.6658 - acc: 0.6104\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 17s 867ms/step - loss: 0.5772 - acc: 0.8292\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 17s 865ms/step - loss: 0.3730 - acc: 0.8646\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 17s 862ms/step - loss: 0.2660 - acc: 0.9208\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "15/15 [==============================] - 5s 360ms/step - loss: 0.1551 - acc: 0.9625\n",
      "Test set : \n",
      "\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.1549 - acc: 0.9750\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 18s 883ms/step - loss: 0.7365 - acc: 0.5104\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 18s 878ms/step - loss: 0.6972 - acc: 0.5396\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 18s 890ms/step - loss: 0.6943 - acc: 0.5125\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 18s 879ms/step - loss: 0.6899 - acc: 0.5083\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 18s 883ms/step - loss: 0.6909 - acc: 0.4896\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 18s 884ms/step - loss: 0.6819 - acc: 0.5479\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 18s 884ms/step - loss: 0.6660 - acc: 0.5250\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 18s 881ms/step - loss: 0.6820 - acc: 0.5271\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 18s 877ms/step - loss: 0.6120 - acc: 0.6021\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 18s 885ms/step - loss: 0.5106 - acc: 0.7500\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "15/15 [==============================] - 6s 369ms/step - loss: 0.5599 - acc: 0.5000\n",
      "Test set : \n",
      "\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.5596 - acc: 0.5000\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 16s 804ms/step - loss: 0.7426 - acc: 0.5146\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 16s 804ms/step - loss: 0.7047 - acc: 0.4938\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 16s 805ms/step - loss: 0.6943 - acc: 0.4917\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 16s 822ms/step - loss: 0.6919 - acc: 0.5729\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 15s 768ms/step - loss: 0.6874 - acc: 0.5271\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 15s 768ms/step - loss: 0.7016 - acc: 0.4979\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 15s 767ms/step - loss: 0.6792 - acc: 0.6208\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 15s 771ms/step - loss: 0.6964 - acc: 0.5250\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 15s 767ms/step - loss: 0.6796 - acc: 0.5437\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 16s 777ms/step - loss: 0.6719 - acc: 0.5896\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "15/15 [==============================] - 5s 361ms/step - loss: 0.6634 - acc: 0.5542\n",
      "Test set : \n",
      "\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6732 - acc: 0.5417\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "data amount of 600 leading to accuracy of 70.50000071525574 +- 22.42642396984373\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_78 (Conv2D)           (None, 398, 398, 32)      320       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_78 (Averag (None, 132, 132, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 130, 130, 16)      4624      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_79 (Averag (None, 65, 65, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 63, 63, 8)         1160      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_80 (Averag (None, 31, 31, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 7688)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 7689      \n",
      "=================================================================\n",
      "Total params: 13,793\n",
      "Trainable params: 13,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.7300 - acc: 0.5156\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.6944 - acc: 0.5141\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.6831 - acc: 0.5500\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.7112 - acc: 0.4828\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.6911 - acc: 0.5484\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.6761 - acc: 0.5734\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.5760 - acc: 0.6797\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.4079 - acc: 0.8406\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.2689 - acc: 0.9281\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.1484 - acc: 0.9812\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "20/20 [==============================] - 8s 381ms/step - loss: 0.1105 - acc: 0.9797\n",
      "Test set : \n",
      "\n",
      "5/5 [==============================] - 1s 265ms/step - loss: 0.1159 - acc: 0.9750\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.7315 - acc: 0.5203\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.6957 - acc: 0.5078\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.6951 - acc: 0.5250\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.6841 - acc: 0.5094\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.6321 - acc: 0.7250\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.6773 - acc: 0.5719\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.5906 - acc: 0.6359\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.4843 - acc: 0.7766\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.4236 - acc: 0.8531\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.1840 - acc: 0.9766\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "20/20 [==============================] - 7s 369ms/step - loss: 0.1389 - acc: 1.0000\n",
      "Test set : \n",
      "\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.1393 - acc: 1.0000\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.7303 - acc: 0.4750\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.6950 - acc: 0.5016\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.6933 - acc: 0.5312\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.6929 - acc: 0.5172\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.6891 - acc: 0.6328\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.7002 - acc: 0.4781\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.6859 - acc: 0.5437\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.6802 - acc: 0.5109\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.6695 - acc: 0.5844\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.5400 - acc: 0.7281\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "20/20 [==============================] - 7s 357ms/step - loss: 0.4163 - acc: 0.7500\n",
      "Test set : \n",
      "\n",
      "5/5 [==============================] - 1s 276ms/step - loss: 0.4368 - acc: 0.7437\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.7306 - acc: 0.4984\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.6949 - acc: 0.4906\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 21s 939ms/step - loss: 0.6972 - acc: 0.5141\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 21s 935ms/step - loss: 0.6980 - acc: 0.5219\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 21s 932ms/step - loss: 0.6846 - acc: 0.5188\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 21s 939ms/step - loss: 0.6892 - acc: 0.5547\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 20s 929ms/step - loss: 0.6616 - acc: 0.6406\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 21s 933ms/step - loss: 0.6451 - acc: 0.5625\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 21s 936ms/step - loss: 0.5651 - acc: 0.7375\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 21s 948ms/step - loss: 0.4338 - acc: 0.7922\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "20/20 [==============================] - 7s 373ms/step - loss: 0.4592 - acc: 0.5000\n",
      "Test set : \n",
      "\n",
      "5/5 [==============================] - 2s 311ms/step - loss: 0.4636 - acc: 0.5000\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.7312 - acc: 0.5016\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.6898 - acc: 0.5109\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.6697 - acc: 0.5953\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.5888 - acc: 0.7484\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.3508 - acc: 0.9109\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.2610 - acc: 0.9203\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.1689 - acc: 0.9719\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.0897 - acc: 0.9937\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.0618 - acc: 0.9984\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.0637 - acc: 0.9969\n",
      "\n",
      "Evaluation of the model : \n",
      "\n",
      "Train set : \n",
      "\n",
      "20/20 [==============================] - 7s 375ms/step - loss: 0.0531 - acc: 1.0000\n",
      "Test set : \n",
      "\n",
      "5/5 [==============================] - 1s 297ms/step - loss: 0.0535 - acc: 1.0000\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "data amount of 800 leading to accuracy of 84.375 +- 19.70881838299092\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dic_vals = {}\n",
    "dic_errs = {}\n",
    "for batch_size, half_data_amount in zip([8, 10, 12, 15, 25, 30],[40, 60, 100, 200, 300, 400]):\n",
    "    X,y = load_data(half_data_amount, amplitude=0.5)\n",
    "    \n",
    "    skfold = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    acc_per_fold = []\n",
    "    loss_per_fold = []\n",
    "\n",
    "    for train, test in skfold.split(X,y):\n",
    "\n",
    "        #define the model\n",
    "        model = keras.models.Sequential()\n",
    "\n",
    "        model.add(keras.layers.Conv2D(32, (3, 3), activation='tanh', input_shape=X.shape[1:]))\n",
    "        model.add(keras.layers.AveragePooling2D((3, 3)))\n",
    "\n",
    "        model.add(keras.layers.Conv2D(16, (3, 3), activation='tanh'))\n",
    "        model.add(keras.layers.AveragePooling2D((2, 2)))\n",
    "\n",
    "        model.add(keras.layers.Conv2D(8, (3, 3), activation='tanh'))\n",
    "        model.add(keras.layers.AveragePooling2D((2, 2)))\n",
    "\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(l=0.05)))\n",
    "\n",
    "        if len(acc_per_fold)==0 : model.summary()\n",
    "        #compile the model\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "        #fit the model\n",
    "        history = model.fit(X[train], y[train], epochs=10, batch_size=batch_size, verbose=1)\n",
    "\n",
    "        #evaluate the model\n",
    "        print('\\nEvaluation of the model : \\n')\n",
    "        print('Train set : \\n')\n",
    "        model.evaluate(X[train], y[train])\n",
    "        print('Test set : \\n')\n",
    "        scores = model.evaluate(X[test], y[test])\n",
    "        acc_per_fold.append(scores[1] * 100)\n",
    "        loss_per_fold.append(scores[0])\n",
    "        print(\"\\n-----------------------------------\\n\")\n",
    "    \n",
    "    dic_vals[str(2*half_data_amount)] = np.mean(acc_per_fold)\n",
    "    dic_errs[str(2*half_data_amount)] = np.std(acc_per_fold)\n",
    "    print('data amount of {}'.format(2*half_data_amount) + ' leading to accuracy of {} +- {}'.format(np.mean(acc_per_fold), np.std(acc_per_fold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc48caa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'80': 55.0,\n",
       " '120': 54.166667461395264,\n",
       " '200': 61.00000023841858,\n",
       " '400': 70.24999976158142,\n",
       " '600': 70.50000071525574,\n",
       " '800': 84.375}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "863fa091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'80': 10.752906583803284,\n",
       " '120': 10.206207748266497,\n",
       " '200': 6.819091075755228,\n",
       " '400': 17.507142050288444,\n",
       " '600': 22.42642396984373,\n",
       " '800': 19.70881838299092}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b6a62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
