{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data from database in \"output\" directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, ns-maps are \"no-signal maps\" and ws-maps are \"with signal maps\".\n",
    "\n",
    "The shape is as follows: (samples, features), so that if we have (10,200), it means we have 10 samples with 200 features. Here, the features are the pixel values, and since we have 400x400, there are 160000 features. We the number of samples is chosen in the get_data() function. \n",
    "\n",
    "get_data(n) should then output X,y where X.shape = $(2n, 160000)$ and y.shape = $(2n,)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(n, amplitude=1, dataset='dataset_1'):\n",
    "    '''\n",
    "    returns the maps with and without cosmic string signal with appropriate labels (index matching).\n",
    "    \n",
    "    Parameters:\n",
    "    --------------\n",
    "    n : number of maps to be fetched for each type of map (thus it returns 2*l maps)\n",
    "    \n",
    "    amplitude : multiplicative factor used to augment the cosmic string signal\n",
    "    \n",
    "    dataset : the dataset from which the data is pulled\n",
    "    \n",
    "    '''\n",
    "    #load the data\n",
    "    path_ns = \"../data/\" + dataset + \"/ns-maps/\"\n",
    "    path_ws = \"../data/\" + dataset + \"/ws-maps/\"\n",
    "    \n",
    "    #here the shape of arr_ns is n rows by 400^2 pixels, so (n,160000)\n",
    "    arr_ns = np.array([np.load(path_ns + \"ns-map\"+str(i)+\".npy\").flatten() for i in range(n)]) #no signal maps (y=0)\n",
    "    \n",
    "    arr_ws_noise = np.array([np.load(path_ws + \"noise/noise\"+str(i)+\".npy\").flatten() for i in range(n)])\n",
    "    arr_ws_signal = np.array([np.load(path_ws + \"signal/signal\"+str(i)+\".npy\").flatten() for i in range(n)])\n",
    "    \n",
    "    #here we combine the signal map and noise maps. We can add these this way by construction of arr_ws_noise and arr_ns_signal\n",
    "    arr_ws = amplitude*arr_ws_signal + arr_ws_noise #with signal maps (y=1)\n",
    "    \n",
    "    #labels \n",
    "    y = np.append(np.zeros(n), np.ones(n))\n",
    "    \n",
    "    #an array of the form (n + n, 400^2) where the first n maps contain no signal and the last n do.\n",
    "    X = np.concatenate((arr_ns,arr_ws),axis=0)\n",
    "    \n",
    "    #we return a shuffled version of the data\n",
    "    return shuffle(X, y, random_state=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_check_reg(n=100, n_splits=5,n_repeats=3, amplitude=10):\n",
    "    '''\n",
    "    fits the logistic regression model to the data. Used k-fold cross validation and returns the mean score and deviation.\n",
    "    '''\n",
    "    X, y = get_data(n, amplitude=amplitude)\n",
    "    \n",
    "    steps = list()\n",
    "    steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', LogisticRegression()))\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    \n",
    "    cv = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=1)\n",
    "\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    return scores, np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.9  , 0.9  , 0.975, 0.75 , 0.8  , 0.825, 0.875, 0.95 , 0.85 ,\n",
       "        0.85 , 0.9  , 0.9  , 0.85 , 0.925, 0.925]),\n",
       " 0.8783333333333335,\n",
       " 0.05691123692987958)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_check_reg(n=100, amplitude=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.875  , 0.84375, 0.78125, 0.78125, 0.90625, 0.75   , 0.84375,\n",
       "        0.9375 , 0.84375, 0.84375, 0.6875 , 0.84375, 0.875  , 0.96875,\n",
       "        0.65625]),\n",
       " 0.8291666666666667,\n",
       " 0.08296794896558284)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_check_reg(n=80, amplitude=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.    , 0.8125, 0.9375, 0.5   , 0.9375, 0.875 , 0.75  , 0.9375,\n",
       "        0.75  , 0.75  , 0.9375, 0.75  , 0.875 , 0.9375, 0.8125]),\n",
       " 0.8375,\n",
       " 0.12247448713915891)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_check_reg(n=40, amplitude=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
