{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from utilities import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_data(100, amplitude=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 400, 400, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape #2n samples of 400x400 pixels, with a depth of 1 (greyscale type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "skfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.0894 - acc: 0.5125\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6972 - acc: 0.4812\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6860 - acc: 0.4625\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6621 - acc: 0.5688\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.5756 - acc: 0.8188\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.5861 - acc: 0.7250\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.4906 - acc: 0.8375\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.5009 - acc: 0.8125\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.4411 - acc: 0.8062\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.3404 - acc: 0.9375\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.4085 - acc: 0.9000\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2587 - acc: 0.9438\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2233 - acc: 0.9500\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1769 - acc: 0.9688\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.2242 - acc: 0.9187\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1008 - acc: 1.0000\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1833 - acc: 0.9312\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0980 - acc: 1.0000\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0279 - acc: 1.0000\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1682 - acc: 0.9250\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0479 - acc: 1.0000\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2434 - acc: 0.8500\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2486 - acc: 0.9187\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0108 - acc: 1.0000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.7712 - acc: 0.4750\n",
      "-----------------------------------\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.1404 - acc: 0.4375\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.7154 - acc: 0.5125\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.6749 - acc: 0.4625\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.6518 - acc: 0.7375\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.5934 - acc: 0.7563\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.5706 - acc: 0.8125\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.5524 - acc: 0.8062\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.5062 - acc: 0.8062\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.4720 - acc: 0.8438\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.3996 - acc: 0.9187\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.3069 - acc: 0.9438\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.3272 - acc: 0.8875\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.2097 - acc: 0.9812\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.2027 - acc: 0.9438\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1229 - acc: 1.0000\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2929 - acc: 0.9000\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0794 - acc: 1.0000\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0816 - acc: 1.0000\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0924 - acc: 0.9875\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0349 - acc: 1.0000\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1405 - acc: 0.9500\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1292 - acc: 0.9125\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0281 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2232 - acc: 0.9125\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.8590 - acc: 0.4250\n",
      "-----------------------------------\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.8702 - acc: 0.5125\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.6767 - acc: 0.5500\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6824 - acc: 0.5813\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6504 - acc: 0.5813\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6178 - acc: 0.7500\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.5232 - acc: 0.8188\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.5670 - acc: 0.7750\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.4473 - acc: 0.8813\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.3491 - acc: 0.8938\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.3783 - acc: 0.8687\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.2683 - acc: 0.9375\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2853 - acc: 0.9625\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1775 - acc: 0.9812\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1454 - acc: 1.0000\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1771 - acc: 0.9375\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1089 - acc: 0.9750\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0829 - acc: 0.9625\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0708 - acc: 1.0000\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2219 - acc: 0.9312\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0676 - acc: 1.0000\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 15s 2s/step - loss: 0.1522 - acc: 0.9312\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0445 - acc: 1.0000\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0074 - acc: 1.0000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.7586 - acc: 0.4500\n",
      "-----------------------------------\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.8049 - acc: 0.4437\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.7061 - acc: 0.5562\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6805 - acc: 0.5938\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6873 - acc: 0.7188\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6678 - acc: 0.6812\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.5888 - acc: 0.6500\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.5617 - acc: 0.7563\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.4630 - acc: 0.8500\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.4079 - acc: 0.8500\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.4555 - acc: 0.7812\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.3368 - acc: 0.8625\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.3378 - acc: 0.9187\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2120 - acc: 0.9500\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2467 - acc: 0.9125\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1152 - acc: 1.0000\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2410 - acc: 0.9375\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1168 - acc: 0.9875\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0344 - acc: 1.0000\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2553 - acc: 0.9062\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1125 - acc: 1.0000\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.3293 - acc: 0.9187\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0320 - acc: 1.0000\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1386 - acc: 0.9250\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0054 - acc: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x00000250D2D33F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.7649 - acc: 0.4250\n",
      "-----------------------------------\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.3964 - acc: 0.5312\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6976 - acc: 0.4625\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6888 - acc: 0.5437\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6911 - acc: 0.5437\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.6893 - acc: 0.6250\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6970 - acc: 0.4750\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6816 - acc: 0.6625\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6832 - acc: 0.5938\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6624 - acc: 0.6375\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6301 - acc: 0.6313\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.5535 - acc: 0.8062\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.5836 - acc: 0.7750\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.4809 - acc: 0.8000\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.4203 - acc: 0.8875\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.3314 - acc: 0.9125\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.4112 - acc: 0.8438\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.2953 - acc: 0.9062\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.2849 - acc: 0.9000\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.2324 - acc: 0.9312\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.2271 - acc: 0.9062\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.1636 - acc: 0.9625\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0922 - acc: 1.0000\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.1094 - acc: 0.9812\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0957 - acc: 1.0000\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0879 - acc: 0.9937\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.1408 - acc: 0.9500\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0157 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000250884CEEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.9561 - acc: 0.5250\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "for train, test in skfold.split(X,y):\n",
    "    \n",
    "    #define the model\n",
    "    model = keras.Sequential([\n",
    "        \n",
    "    keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=X.shape[1:]),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        \n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=X.shape[1:]),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        \n",
    "                \n",
    "    keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=X.shape[1:]),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        \n",
    "                \n",
    "    keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=X.shape[1:]),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=512, activation='relu'),\n",
    "    keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.RMSprop(lr=1e-4), metrics=['acc'])\n",
    "    \n",
    "    #fit the model\n",
    "    history = model.fit(X[train], y[train], epochs=30, batch_size=20)\n",
    "    \n",
    "    #evaluate the model\n",
    "    scores = model.evaluate(X[test], y[test])\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    print(\"-----------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47.49999940395355,\n",
       " 42.500001192092896,\n",
       " 44.999998807907104,\n",
       " 42.500001192092896,\n",
       " 52.49999761581421]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_per_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('CNN_1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
